{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc5bbfa9",
   "metadata": {},
   "source": [
    "# CAR GAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc881e21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.6.1 (SDL 2.28.4, Python 3.9.6)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import cvzone\n",
    "import random\n",
    "from cvzone.HandTrackingModule import HandDetector\n",
    "from cvzone.FaceMeshModule import FaceMeshDetector\n",
    "import numpy as np\n",
    "import pygame\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "20f29c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize pygame mixer\n",
    "pygame.mixer.init()\n",
    "point_s = pygame.mixer.Sound(\"point.wav\")\n",
    "gameover_s = pygame.mixer.Sound(\"gameOver.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "247e2807",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1753121032.630607 45041718 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88.1), renderer: Apple M1\n",
      "I0000 00:00:1753121032.653561 45041718 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88.1), renderer: Apple M1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "W0000 00:00:1753121032.666893 45042570 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1753121032.667474 45042559 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1753121032.674393 45042570 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1753121032.697945 45042559 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    }
   ],
   "source": [
    "# Initialize webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(3, 640)\n",
    "cap.set(4, 480)\n",
    "\n",
    "detector = HandDetector(detectionCon=0.8, maxHands=1)\n",
    "faceDetector = FaceMeshDetector(maxFaces=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d6e1e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load images (with error handling)\n",
    "try:\n",
    "    car_img = cv2.imread('car.png', cv2.IMREAD_UNCHANGED)\n",
    "    car_img = cv2.resize(car_img, (100, 100))\n",
    "except:\n",
    "    car_img = None\n",
    "\n",
    "try:\n",
    "    obstacle_img = cv2.imread('obstacle.png', cv2.IMREAD_UNCHANGED)\n",
    "    obstacle_img = cv2.resize(obstacle_img, (80, 80))\n",
    "except:\n",
    "    obstacle_img = None\n",
    "\n",
    "try:\n",
    "    coin_img = cv2.imread('coin.png', cv2.IMREAD_UNCHANGED)\n",
    "    coin_img = cv2.resize(coin_img, (40, 40))\n",
    "except:\n",
    "    coin_img = None\n",
    "\n",
    "try:\n",
    "    mask_img = cv2.imread('spiderman.png', cv2.IMREAD_UNCHANGED)\n",
    "except:\n",
    "    mask_img = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b4fcd88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Game variables\n",
    "player_x = 110  # Center lane x\n",
    "lanes = [10, 110, 210]  # Left, center, right lane x positions\n",
    "player_y = 350\n",
    "player_width = 100\n",
    "player_height = 100\n",
    "\n",
    "objects = []  # [type, x, y, width, height]\n",
    "\n",
    "score = 0\n",
    "gameOver = False\n",
    "game_started = False\n",
    "\n",
    "# Timer for object spawning\n",
    "last_spawn_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b307443",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ankitkumar/Library/Python/3.9/lib/python/site-packages/google/protobuf/symbol_database.py:55: UserWarning: SymbolDatabase.GetPrototype() is deprecated. Please use message_factory.GetMessageClass() instead. SymbolDatabase.GetPrototype() will be removed soon.\n",
      "  warnings.warn('SymbolDatabase.GetPrototype() is deprecated. Please '\n",
      "2025-07-21 23:34:01.957 Python[92544:45041718] WARNING: Secure coding is automatically enabled for restorable state! However, not on all supported macOS versions of this application. Opt-in to secure coding explicitly by implementing NSApplicationDelegate.applicationSupportsSecureRestorableState:.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 35\u001b[0m\n\u001b[1;32m     32\u001b[0m canvas \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((\u001b[38;5;241m480\u001b[39m, \u001b[38;5;241m640\u001b[39m, \u001b[38;5;241m3\u001b[39m), dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39muint8)\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# Left half: webcam feed with hand tracking and mask\u001b[39;00m\n\u001b[0;32m---> 35\u001b[0m hands, img \u001b[38;5;241m=\u001b[39m \u001b[43mdetector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfindHands\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflipType\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m# Create hand mask (for visualization)\u001b[39;00m\n\u001b[1;32m     38\u001b[0m hand_mask \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros_like(img)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/cvzone/HandTrackingModule.py:55\u001b[0m, in \u001b[0;36mHandDetector.findHands\u001b[0;34m(self, img, draw, flipType)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;124;03mFinds hands in a BGR image.\u001b[39;00m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;124;03m:param img: Image to find the hands in.\u001b[39;00m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;124;03m:param draw: Flag to draw the output on the image.\u001b[39;00m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;124;03m:return: Image with or without drawings\u001b[39;00m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     54\u001b[0m imgRGB \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mcvtColor(img, cv2\u001b[38;5;241m.\u001b[39mCOLOR_BGR2RGB)\n\u001b[0;32m---> 55\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhands\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimgRGB\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m allHands \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     57\u001b[0m h, w, c \u001b[38;5;241m=\u001b[39m img\u001b[38;5;241m.\u001b[39mshape\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/mediapipe/python/solutions/hands.py:153\u001b[0m, in \u001b[0;36mHands.process\u001b[0;34m(self, image)\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mprocess\u001b[39m(\u001b[38;5;28mself\u001b[39m, image: np\u001b[38;5;241m.\u001b[39mndarray) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m NamedTuple:\n\u001b[1;32m    133\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Processes an RGB image and returns the hand landmarks and handedness of each detected hand.\u001b[39;00m\n\u001b[1;32m    134\u001b[0m \n\u001b[1;32m    135\u001b[0m \u001b[38;5;124;03m  Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;124;03m         right hand) of the detected hand.\u001b[39;00m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 153\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mimage\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/mediapipe/python/solution_base.py:340\u001b[0m, in \u001b[0;36mSolutionBase.process\u001b[0;34m(self, input_data)\u001b[0m\n\u001b[1;32m    334\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    335\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_graph\u001b[38;5;241m.\u001b[39madd_packet_to_input_stream(\n\u001b[1;32m    336\u001b[0m         stream\u001b[38;5;241m=\u001b[39mstream_name,\n\u001b[1;32m    337\u001b[0m         packet\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_packet(input_stream_type,\n\u001b[1;32m    338\u001b[0m                                  data)\u001b[38;5;241m.\u001b[39mat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_simulated_timestamp))\n\u001b[0;32m--> 340\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_graph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait_until_idle\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    341\u001b[0m \u001b[38;5;66;03m# Create a NamedTuple object where the field names are mapping to the graph\u001b[39;00m\n\u001b[1;32m    342\u001b[0m \u001b[38;5;66;03m# output stream names.\u001b[39;00m\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_stream_type_info \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    success, img = cap.read()\n",
    "    if not success:\n",
    "        break\n",
    "    img = cv2.flip(img, 1)\n",
    "\n",
    "    # Detect face mesh and overlay mask\n",
    "    img, faces = faceDetector.findFaceMesh(img, draw=False)\n",
    "    if faces and mask_img is not None:\n",
    "        face = faces[0]\n",
    "        \n",
    "        # Get key landmarks for alignment\n",
    "        left_eye = face[145]\n",
    "        right_eye = face[374]\n",
    "        nose = face[1]\n",
    "        \n",
    "        # Calculate mask width based on eye distance\n",
    "        eye_width = int(((right_eye[0] - left_eye[0]) ** 2 + (right_eye[1] - left_eye[1]) ** 2) ** 0.5 * 2.5)\n",
    "        mask_height = int(eye_width * mask_img.shape[0] / mask_img.shape[1])\n",
    "        \n",
    "        # Position: center mask at nose tip\n",
    "        x1 = int(nose[0] - eye_width // 2)\n",
    "        y1 = int(nose[1] - mask_height // 2)\n",
    "        \n",
    "        # Resize mask\n",
    "        resized_mask = cv2.resize(mask_img, (eye_width, mask_height))\n",
    "        \n",
    "        # Overlay mask\n",
    "        img = cvzone.overlayPNG(img, resized_mask, [x1, y1])\n",
    "\n",
    "    # Split screen canvas\n",
    "    canvas = np.zeros((480, 640, 3), dtype=np.uint8)\n",
    "\n",
    "    # Left half: webcam feed with hand tracking and mask\n",
    "    hands, img = detector.findHands(img, flipType=False)\n",
    "    \n",
    "    # Create hand mask (for visualization)\n",
    "    hand_mask = np.zeros_like(img)\n",
    "    if hands:\n",
    "        hand = hands[0]\n",
    "        for lm in hand[\"lmList\"]:\n",
    "            cv2.circle(hand_mask, (lm[0], lm[1]), 5, (255, 0, 255), cv2.FILLED)\n",
    "        \n",
    "        if hasattr(detector, 'handConnections'):\n",
    "            connections = detector.handConnections\n",
    "        else:\n",
    "            connections = [[0,1],[1,2],[2,3],[3,4],\n",
    "                           [0,5],[5,6],[6,7],[7,8],\n",
    "                           [5,9],[9,10],[10,11],[11,12],\n",
    "                           [9,13],[13,14],[14,15],[15,16],\n",
    "                           [13,17],[17,18],[18,19],[19,20],[0,17]]\n",
    "        \n",
    "        for connection in connections:\n",
    "            x1, y1 = hand[\"lmList\"][connection[0]][0], hand[\"lmList\"][connection[0]][1]\n",
    "            x2, y2 = hand[\"lmList\"][connection[1]][0], hand[\"lmList\"][connection[1]][1]\n",
    "            cv2.line(hand_mask, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "    \n",
    "    img_with_mask = cv2.addWeighted(img, 0.7, hand_mask, 0.3, 0)\n",
    "    img_resized = cv2.resize(img_with_mask, (320, 480))\n",
    "    canvas[:, :320] = img_resized\n",
    "\n",
    "    # Right half: game area\n",
    "    game_area = np.zeros((480, 320, 3), dtype=np.uint8)\n",
    "    game_area[:, :] = (50, 50, 50)  # Dark grey background\n",
    "\n",
    "    for y in range(0, 480, 40):\n",
    "        cv2.rectangle(game_area, (50, y), (70, y+20), (255, 255, 255), -1)\n",
    "        cv2.rectangle(game_area, (170, y), (190, y+20), (255, 255, 255), -1)\n",
    "\n",
    "    if not game_started:\n",
    "        cv2.putText(game_area, \"TEMPLE RUN\", (40, 180), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 0), 3)\n",
    "        cv2.putText(game_area, \"Press SPACE to Start\", (20, 240), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "        canvas[:, 320:] = game_area\n",
    "        cv2.imshow(\"Temple Run Split Screen\", canvas)\n",
    "        key = cv2.waitKey(1)\n",
    "        if key == ord(' '):\n",
    "            game_started = True\n",
    "        elif key == ord('q'):\n",
    "            break\n",
    "        continue\n",
    "\n",
    "    if gameOver:\n",
    "        cv2.putText(game_area, \"GAME OVER\", (30, 180), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 3)\n",
    "        cv2.putText(game_area, f\"Score: {score}\", (80, 220), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2)\n",
    "        cv2.putText(game_area, \"Press SPACE to Restart\", (10, 260), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)\n",
    "        canvas[:, 320:] = game_area\n",
    "        cv2.imshow(\"Temple Run Split Screen\", canvas)\n",
    "        key = cv2.waitKey(1)\n",
    "        if key == ord(' '):\n",
    "            gameOver = False\n",
    "            score = 0\n",
    "            objects.clear()\n",
    "            game_started = True\n",
    "        elif key == ord('q'):\n",
    "            break\n",
    "        continue\n",
    "\n",
    "    if hands and not gameOver:\n",
    "        xHand = hands[0]['lmList'][8][0]\n",
    "        if xHand < 213:\n",
    "            player_x = lanes[0]\n",
    "        elif xHand < 426:\n",
    "            player_x = lanes[1]\n",
    "        else:\n",
    "            player_x = lanes[2]\n",
    "\n",
    "    if car_img is not None:\n",
    "        game_area = cvzone.overlayPNG(game_area, car_img, [player_x, player_y])\n",
    "    else:\n",
    "        cv2.rectangle(game_area, (player_x, player_y), (player_x + player_width, player_y + player_height), (255, 0, 0), -1)\n",
    "        cv2.rectangle(game_area, (player_x, player_y), (player_x + player_width, player_y + player_height), (0, 0, 0), 3)\n",
    "\n",
    "    current_time = time.time()\n",
    "    if current_time - last_spawn_time > 1 and not gameOver:\n",
    "        obj_type = random.choice(['obs', 'coin'])\n",
    "        lane_x = random.choice(lanes)\n",
    "        if obj_type == 'obs':\n",
    "            objects.append(['obs', lane_x, -80, 80, 80])\n",
    "        else:\n",
    "            objects.append(['coin', lane_x + 30, -60, 40, 40])\n",
    "        last_spawn_time = current_time\n",
    "\n",
    "    for obj in objects[:]:\n",
    "        if not gameOver:\n",
    "            obj[2] += 10\n",
    "\n",
    "        if obj[0] == 'obs':\n",
    "            if obstacle_img is not None:\n",
    "                game_area = cvzone.overlayPNG(game_area, obstacle_img, [obj[1], obj[2]])\n",
    "            else:\n",
    "                cv2.circle(game_area, (obj[1] + 40, obj[2] + 40), 40, (0, 0, 255), -1)\n",
    "                cv2.circle(game_area, (obj[1] + 40, obj[2] + 40), 40, (0, 0, 0), 3)\n",
    "            \n",
    "            if not gameOver:\n",
    "                player_rect = [player_x, player_y, player_width, player_height]\n",
    "                obstacle_rect = [obj[1], obj[2], obj[3], obj[4]]\n",
    "                \n",
    "                if (player_rect[0] < obstacle_rect[0] + obstacle_rect[2] and\n",
    "                    player_rect[0] + player_rect[2] > obstacle_rect[0] and\n",
    "                    player_rect[1] < obstacle_rect[1] + obstacle_rect[3] and\n",
    "                    player_rect[1] + player_rect[3] > obstacle_rect[1]):\n",
    "                    gameover_s.play()\n",
    "                    gameOver = True\n",
    "        else:\n",
    "            if coin_img is not None:\n",
    "                game_area = cvzone.overlayPNG(game_area, coin_img, [obj[1], obj[2]])\n",
    "            else:\n",
    "                cv2.ellipse(game_area, (obj[1] + 20, obj[2] + 20), (20, 20), 0, 0, 360, (0, 255, 255), -1)\n",
    "                cv2.ellipse(game_area, (obj[1] + 20, obj[2] + 20), (20, 20), 0, 0, 360, (0, 0, 0), 2)\n",
    "            \n",
    "            if not gameOver:\n",
    "                player_rect = [player_x, player_y, player_width, player_height]\n",
    "                coin_rect = [obj[1], obj[2], obj[3], obj[4]]\n",
    "                \n",
    "                if (player_rect[0] < coin_rect[0] + coin_rect[2] and\n",
    "                    player_rect[0] + player_rect[2] > coin_rect[0] and\n",
    "                    player_rect[1] < coin_rect[1] + coin_rect[3] and\n",
    "                    player_rect[1] + player_rect[3] > coin_rect[1]):\n",
    "                    score += 1\n",
    "                    point_s.play()\n",
    "                    objects.remove(obj)\n",
    "\n",
    "        if obj[2] > 480:\n",
    "            objects.remove(obj)\n",
    "\n",
    "    cv2.putText(game_area, f\"Score: {score}\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
    "\n",
    "    canvas[:, 320:] = game_area\n",
    "\n",
    "    cv2.imshow(\"Temple Run Split Screen\", canvas)\n",
    "    key = cv2.waitKey(1)\n",
    "    if key == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
